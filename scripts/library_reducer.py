#!/usr/bin/env python3
"""Library reducer - tag items for deletion based on analysis.

This script reads the CSV report generated by library_analyzer.py and tags
items in Radarr/Sonarr with "delete-candidate" for manual review and deletion.

IMPORTANT: This script does NOT delete files. It only tags items in Radarr/Sonarr.
You must manually review tagged items and delete via the Radarr/Sonarr UI.

Features:
- Load analysis CSV report
- Filter by score threshold (default: >= 80)
- Backup metadata before tagging
- Tag items in Radarr/Sonarr with "delete-candidate"
- Let user manually delete via UI (proper cleanup)
- Comprehensive logging

Usage:
    # Dry-run mode (default - shows what would be tagged)
    python3 scripts/library_reducer.py --dry-run --report reports/library_analysis_2025-11-29.csv

    # Execute mode (actually tag items)
    python3 scripts/library_reducer.py --execute --report reports/library_analysis_2025-11-29.csv

    # Custom score threshold (default: 80)
    python3 scripts/library_reducer.py --execute --report report.csv --threshold 85

    # Custom tag name
    python3 scripts/library_reducer.py --execute --report report.csv --tag "to-delete"
"""

import sys
import argparse
import os
import csv
import json
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any

# Add parent directory to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent))

from utils.config_loader import load_config
from utils.logger import setup_logging
from utils.ntfy_notifier import create_notifier
from utils.validators import acquire_lock
from utils.api_clients import RadarrAPI, SonarrAPI, APIError


def load_analysis_report(report_path: str, threshold: int) -> List[Dict[str, Any]]:
    """Load analysis CSV and filter by score threshold.

    Args:
        report_path: Path to CSV report
        threshold: Minimum score for deletion candidates

    Returns:
        List of candidate dictionaries

    Raises:
        FileNotFoundError: If report file doesn't exist
    """
    if not os.path.exists(report_path):
        raise FileNotFoundError(f"Report file not found: {report_path}")

    candidates = []

    with open(report_path, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)

        for row in reader:
            try:
                score = int(row['Score'])
                if score >= threshold:
                    candidates.append({
                        'title': row['Title'],
                        'type': row['Type'],
                        'id': int(row['ID']),
                        'score': score,
                        'reason': row['Reason'],
                        'quality': row['Quality'],
                        'size_gb': float(row['Size_GB']),
                        'path': row['Path']
                    })
            except (ValueError, KeyError) as e:
                # Skip malformed rows
                continue

    return candidates


def backup_metadata(item: Dict[str, Any], backup_dir: str) -> str:
    """Backup item metadata before tagging for deletion.

    Args:
        item: Item dictionary
        backup_dir: Directory for backups

    Returns:
        Path to backup file
    """
    # Create backup directory
    os.makedirs(backup_dir, exist_ok=True)

    # Generate filename
    timestamp = datetime.now().strftime('%Y-%m-%d_%H%M%S')
    safe_title = "".join(c for c in item['title'] if c.isalnum() or c in (' ', '-', '_'))[:50]
    filename = f"{timestamp}_{item['type']}_{safe_title}.json"
    backup_path = os.path.join(backup_dir, filename)

    # Save metadata
    with open(backup_path, 'w', encoding='utf-8') as f:
        json.dump({
            'title': item['title'],
            'type': item['type'],
            'id': item['id'],
            'score': item['score'],
            'reason': item['reason'],
            'quality': item['quality'],
            'size_gb': item['size_gb'],
            'path': item['path'],
            'tagged_at': datetime.now().isoformat(),
            'action': 'tagged_for_deletion'
        }, f, indent=2)

    return backup_path


def tag_items(
    candidates: List[Dict],
    config: Dict,
    logger,
    tag_name: str = 'delete-candidate',
    dry_run: bool = False
) -> Dict[str, int]:
    """Tag items in Radarr/Sonarr for deletion.

    Args:
        candidates: List of candidate items
        config: Configuration dictionary
        logger: Logger instance
        tag_name: Tag to add (default: 'delete-candidate')
        dry_run: If True, don't actually tag items

    Returns:
        Dictionary with stats (movies_tagged, series_tagged, failed)
    """
    stats = {
        'movies_tagged': 0,
        'series_tagged': 0,
        'failed': 0
    }

    # Initialize API clients
    radarr = RadarrAPI(config['radarr']['url'], config['radarr']['api_key'])
    sonarr = SonarrAPI(config['sonarr']['url'], config['sonarr']['api_key'])

    backup_dir = os.path.join(config['paths']['backups'], 'deleted_items')

    # Group by type
    movies = [c for c in candidates if c['type'] == 'movie']
    series = [c for c in candidates if c['type'] == 'series']

    # Tag movies
    if movies:
        logger.info(f"\nTagging {len(movies)} movies...")

        for item in movies:
            try:
                # Backup metadata
                if config['safety']['backup_metadata']:
                    backup_path = backup_metadata(item, backup_dir)
                    logger.debug(f"Metadata backed up: {backup_path}")

                if dry_run:
                    logger.info(
                        f"[DRY-RUN] Would tag movie: {item['title']} "
                        f"(score: {item['score']}, {item['size_gb']:.1f}GB)"
                    )
                else:
                    radarr.add_tag(item['id'], tag_name)
                    logger.info(
                        f"TAGGED movie: {item['title']} "
                        f"(score: {item['score']}, {item['size_gb']:.1f}GB)"
                    )
                    stats['movies_tagged'] += 1

            except APIError as e:
                logger.error(f"Failed to tag {item['title']}: {e}")
                stats['failed'] += 1

    # Tag series
    if series:
        logger.info(f"\nTagging {len(series)} series...")

        for item in series:
            try:
                # Backup metadata
                if config['safety']['backup_metadata']:
                    backup_path = backup_metadata(item, backup_dir)
                    logger.debug(f"Metadata backed up: {backup_path}")

                if dry_run:
                    logger.info(
                        f"[DRY-RUN] Would tag series: {item['title']} "
                        f"(score: {item['score']}, {item['size_gb']:.1f}GB)"
                    )
                else:
                    sonarr.add_tag(item['id'], tag_name)
                    logger.info(
                        f"TAGGED series: {item['title']} "
                        f"(score: {item['score']}, {item['size_gb']:.1f}GB)"
                    )
                    stats['series_tagged'] += 1

            except APIError as e:
                logger.error(f"Failed to tag {item['title']}: {e}")
                stats['failed'] += 1

    return stats


def reduce_library(
    config: Dict,
    report_path: str,
    threshold: int = 80,
    tag_name: str = 'delete-candidate',
    dry_run: bool = False
) -> bool:
    """Tag items for deletion based on analysis report.

    Args:
        config: Configuration dictionary
        report_path: Path to analysis CSV report
        threshold: Minimum score for deletion candidates
        tag_name: Tag to add to items
        dry_run: If True, don't actually tag items

    Returns:
        True if successful, False otherwise
    """
    logger = setup_logging('library_reducer.log', level=config['logging']['level'])
    notifier = create_notifier(config)

    logger.info("="*60)
    logger.info("LIBRARY REDUCER STARTED")
    logger.info("="*60)

    if dry_run:
        logger.info("DRY-RUN MODE: Items will NOT be tagged")
    else:
        logger.info("EXECUTE MODE: Items WILL be tagged with '{tag_name}'")

    logger.info(f"Report: {report_path}")
    logger.info(f"Score threshold: {threshold}+")

    try:
        with acquire_lock('library_reducer'):
            logger.info("Lock acquired, proceeding with reduction")

            # Load analysis report
            logger.info("Loading analysis report...")
            candidates = load_analysis_report(report_path, threshold)
            logger.info(f"Found {len(candidates)} candidates (score >= {threshold})")

            if not candidates:
                logger.info("No candidates found. Nothing to do.")
                logger.info("="*60)
                return True

            # Show summary
            total_size = sum(c['size_gb'] for c in candidates)
            logger.info(f"Total potential space to free: {total_size:.2f} GB")

            logger.info("\nTop 10 candidates:")
            for i, item in enumerate(candidates[:10], 1):
                logger.info(
                    f"  {i}. [{item['type']}] {item['title']} "
                    f"(score: {item['score']}, {item['size_gb']:.1f}GB) - {item['reason']}"
                )

            # Tag items
            logger.info("\n" + "-"*60)
            stats = tag_items(candidates, config, logger, tag_name, dry_run)

            # Summary
            logger.info("\n" + "="*60)
            logger.info("TAGGING SUMMARY")
            logger.info("="*60)
            logger.info(f"Movies tagged: {stats['movies_tagged']}")
            logger.info(f"Series tagged: {stats['series_tagged']}")
            logger.info(f"Failed: {stats['failed']}")
            logger.info(f"Total tagged: {stats['movies_tagged'] + stats['series_tagged']}")

            if not dry_run and (stats['movies_tagged'] + stats['series_tagged']) > 0:
                logger.info("\n" + "="*60)
                logger.info("NEXT STEPS")
                logger.info("="*60)
                logger.info(f"1. Review tagged items in Radarr/Sonarr")
                logger.info(f"   - Filter by tag: '{tag_name}'")
                logger.info(f"2. Manually delete items via UI when satisfied")
                logger.info(f"3. Radarr/Sonarr will handle proper file cleanup")
                logger.info("="*60)

                # Success notification
                if config['notifications']['ntfy']['send_on_success']:
                    notifier.notify_success(
                        'library_reducer',
                        f'Tagged {stats["movies_tagged"] + stats["series_tagged"]} items for deletion',
                        stats={
                            'movies': stats['movies_tagged'],
                            'series': stats['series_tagged'],
                            'potential_space_gb': f"{total_size:.2f}",
                            'tag': tag_name
                        }
                    )

            logger.info("="*60)
            logger.info("LIBRARY REDUCER COMPLETED SUCCESSFULLY")
            logger.info("="*60)

            return True

    except FileNotFoundError as e:
        error_msg = f"Report file not found: {e}"
        logger.error(error_msg)
        notifier.notify_error('library_reducer', error_msg)
        return False

    except Exception as e:
        error_msg = f"Unexpected error: {e}"
        logger.exception(error_msg)
        notifier.notify_error('library_reducer', error_msg, details=str(e))
        return False


def main():
    """Main entry point."""
    parser = argparse.ArgumentParser(
        description='Tag items for deletion based on analysis report',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Dry-run (show what would be tagged)
  %(prog)s --dry-run --report reports/library_analysis_2025-11-29.csv

  # Execute (actually tag items)
  %(prog)s --execute --report reports/library_analysis_2025-11-29.csv

  # Custom score threshold (default: 80)
  %(prog)s --execute --report report.csv --threshold 85

  # Custom tag name (default: 'delete-candidate')
  %(prog)s --execute --report report.csv --tag "to-delete"

Notes:
  - This script does NOT delete files
  - It only tags items in Radarr/Sonarr for manual review
  - Backups metadata before tagging (if enabled in config)
  - You must manually delete via Radarr/Sonarr UI
  - Score threshold: items with score >= threshold are tagged
  - Default threshold: 80 (immediate deletion candidates)

Workflow:
  1. Run library_analyzer.py to generate report
  2. Review report CSV manually
  3. Run library_reducer.py to tag candidates
  4. Review tagged items in Radarr/Sonarr UI
  5. Manually delete via UI when satisfied
        """
    )

    # Mode selection
    mode_group = parser.add_mutually_exclusive_group(required=True)
    mode_group.add_argument('--dry-run', action='store_true', help='Show what would be tagged (safe)')
    mode_group.add_argument('--execute', action='store_true', help='Actually tag items')

    parser.add_argument('--config', type=str, default='config.yaml', help='Path to configuration file')
    parser.add_argument('--report', type=str, required=True, help='Path to analysis CSV report (required)')
    parser.add_argument('--threshold', type=int, default=80, help='Minimum score for tagging (default: 80)')
    parser.add_argument('--tag', type=str, default='delete-candidate', help='Tag name to add (default: delete-candidate)')

    args = parser.parse_args()

    # Determine mode
    dry_run = args.dry_run

    # Load configuration
    try:
        config = load_config(args.config)
    except Exception as e:
        print(f"ERROR: Failed to load configuration: {e}", file=sys.stderr)
        return 1

    # Run reduction
    success = reduce_library(
        config,
        report_path=args.report,
        threshold=args.threshold,
        tag_name=args.tag,
        dry_run=dry_run
    )

    return 0 if success else 1


if __name__ == '__main__':
    sys.exit(main())
